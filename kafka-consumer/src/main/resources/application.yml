spring:
  application:
    name: kafka-consumer
  kafka:
    bootstrap-servers: ${KAFKA_URL:localhost:29092}
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      auto-offset-reset: latest
      max-poll-records: 500
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      acks: all
      retries: 5
      batch-size: 16384
    properties:
      value.subject.name.strategy: io.confluent.kafka.serializers.subject.TopicRecordNameStrategy
      specific.avro.reader: true
      schema.registry.url: ${KAFKA_SCHEMA_REGISTRY_URL:http://localhost:8083}
      linger.ms: 0

  datasource:
    url: ${DB_URL:jdbc:mysql://localhost:3306/test_db}
    username: ${DB_USERNAME:test_user}
    password: ${DB_PASSWORD:test_password}
    driver-class-name: com.mysql.cj.jdbc.Driver

  data:
    mongodb:
      uri: ${MONGODB_URI:mongodb://test_user:test_password@localhost:27017}
      database: ${MONGODB_DB:test_db}

  jpa:
    open-in-view: false
    hibernate:
      ddl-auto: none
    properties:
      hibernate:
        format_sql: true
        default_batch_fetch_size: 100
        dialect: org.hibernate.dialect.MySQL8Dialect

redis:
  cache:
    host: ${REDIS_CACHE_HOST:localhost}
    port: ${REDIS_CACHE_PORT:6380}
  queue:
    host: ${REDIS_QUEUE_HOST:localhost}
    port: ${REDIS_QUEUE_PORT:6381}

logging:
  level:
    org.springframework.data.mongodb.core.MongoTemplate: DEBUG
    org.mongodb.driver.protocol.command: DEBUG
    org.mongodb.driver.cluster: INFO
    org.hibernate.SQL: debug
    org.hibernate.orm.jdbc.bind: trace